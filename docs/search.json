[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/BlogPost2/index.html",
    "href": "posts/BlogPost2/index.html",
    "title": "Blog Post #2: Big Tech Stock Prices",
    "section": "",
    "text": "These data come from Yahoo Finance via Kaggle, compiled by Evan Gower. This data set consists of 8 variables involved in the daily stock prices and volumes of 14 of the largest tech companies and has 45,088 total observations. This data set includes the daily high and low stock prices of these 14 different tech companies (only recorded on weekdays) from the start of 2010 through the end of 2022. I found this data set from tidytuesday on GitHub from the following URL: https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-02-07/readme.md.\nQuestions of Interest\n\nHow have stock prices changed for these big tech companies over the past 12 years?\nWhich companies get the most yearly trading volume in the most recent year of the data set (2022)?\nFor the most popular company (Apple.com), can we make a model to accurately predict its stock prices?\n\nVariables of Interest\n\ncompany: the full name of the company\nstock_symbol: the stock symbol of the company\ndate: date of observation\nvolume: number of shares traded (buys and sells) for the day\nhigh: the highest market price for the day, in dollars per share\n\n\nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(lubridate)\nlibrary(forecast)\nlibrary(openintro)\nlibrary(broom)\nlibrary(modelr)\ntheme_set(theme_minimal())\n\ntuesdata &lt;- tidytuesdayR::tt_load('2023-02-07')\ntuesdata &lt;- tidytuesdayR::tt_load(2023, week = 6)\n\nbig_tech_stock_prices &lt;- tuesdata$big_tech_stock_prices\nbig_tech_companies &lt;- tuesdata$big_tech_companies\n\nstocks &lt;- big_tech_stock_prices |&gt; \n  left_join(big_tech_companies, by = c(\"stock_symbol\" = \"stock_symbol\")) |&gt;\n  relocate(company) |&gt;\n  mutate(weekday = weekdays(date),\n         month = month(date, label = TRUE),\n         year = year(date))"
  },
  {
    "objectID": "posts/BlogPost2/index.html#big-tech-stock-prices-data-set-introduction",
    "href": "posts/BlogPost2/index.html#big-tech-stock-prices-data-set-introduction",
    "title": "Blog Post #2: Big Tech Stock Prices",
    "section": "",
    "text": "These data come from Yahoo Finance via Kaggle, compiled by Evan Gower. This data set consists of 8 variables involved in the daily stock prices and volumes of 14 of the largest tech companies and has 45,088 total observations. This data set includes the daily high and low stock prices of these 14 different tech companies (only recorded on weekdays) from the start of 2010 through the end of 2022. I found this data set from tidytuesday on GitHub from the following URL: https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-02-07/readme.md.\nQuestions of Interest\n\nHow have stock prices changed for these big tech companies over the past 12 years?\nWhich companies get the most yearly trading volume in the most recent year of the data set (2022)?\nFor the most popular company (Apple.com), can we make a model to accurately predict its stock prices?\n\nVariables of Interest\n\ncompany: the full name of the company\nstock_symbol: the stock symbol of the company\ndate: date of observation\nvolume: number of shares traded (buys and sells) for the day\nhigh: the highest market price for the day, in dollars per share\n\n\nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(lubridate)\nlibrary(forecast)\nlibrary(openintro)\nlibrary(broom)\nlibrary(modelr)\ntheme_set(theme_minimal())\n\ntuesdata &lt;- tidytuesdayR::tt_load('2023-02-07')\ntuesdata &lt;- tidytuesdayR::tt_load(2023, week = 6)\n\nbig_tech_stock_prices &lt;- tuesdata$big_tech_stock_prices\nbig_tech_companies &lt;- tuesdata$big_tech_companies\n\nstocks &lt;- big_tech_stock_prices |&gt; \n  left_join(big_tech_companies, by = c(\"stock_symbol\" = \"stock_symbol\")) |&gt;\n  relocate(company) |&gt;\n  mutate(weekday = weekdays(date),\n         month = month(date, label = TRUE),\n         year = year(date))"
  },
  {
    "objectID": "posts/BlogPost2/index.html#how-have-stock-prices-changed-for-these-big-tech-companies-over-the-past-12-years",
    "href": "posts/BlogPost2/index.html#how-have-stock-prices-changed-for-these-big-tech-companies-over-the-past-12-years",
    "title": "Blog Post #2: Big Tech Stock Prices",
    "section": "How have stock prices changed for these big tech companies over the past 12 years?",
    "text": "How have stock prices changed for these big tech companies over the past 12 years?\n\nyearly_price = stocks |&gt;\n  group_by(stock_symbol, year) |&gt;\n  summarise(mean_price = mean(high),\n            sd_price = sd(high),\n            sample_size = n()) |&gt;\n  mutate(se = sd_price / sqrt(sample_size), ## se for means\n         lower = mean_price - se,\n         upper = mean_price + se) |&gt;\n  left_join(big_tech_companies)\n  \nggplot(data = yearly_price, aes(x = year, y = mean_price, col = company)) +\n  geom_line(linewidth = 0.75) +\n  facet_wrap(~stock_symbol) +\n  theme(axis.text.x.bottom = element_text(size = 6)) +\n  labs(x = \"Year\", y = \"Mean Stock Price\", col = \"Company Name\")\n\n\n\n\nVisual Takeaways: For most of these big tech companies, there is generally an increase in mean stock price over time. This makes sense as tech is still considered a growing industry. Adobe and Netflix both have similar mean price trends: a steady increase in mean price until around 2020, immediately followed by a sharp drop. Most of these companies also see a decline in mean stock price after 2020. Tesla is also an interesting trend to point out: low and constant until 2019 when Tesla stock prices saw a very sharp increase up to almost $300 per share in 2020."
  },
  {
    "objectID": "posts/BlogPost2/index.html#which-companies-get-the-most-yearly-trading-volume-in-the-most-recent-year-of-the-data-set-2022",
    "href": "posts/BlogPost2/index.html#which-companies-get-the-most-yearly-trading-volume-in-the-most-recent-year-of-the-data-set-2022",
    "title": "Blog Post #2: Big Tech Stock Prices",
    "section": "Which companies get the most yearly trading volume in the most recent year of the data set (2022)?",
    "text": "Which companies get the most yearly trading volume in the most recent year of the data set (2022)?\n\nyearly_volume = stocks |&gt;\n  group_by(company, year) |&gt;\n  summarise(mean_volume = mean(volume),\n            sd_volume = sd(volume),\n            sample_size = n()) |&gt;\n  mutate(se = sd_volume / sqrt(sample_size), ## se for means\n         lower = mean_volume - se,\n         upper = mean_volume + se)\n\ntop_5_summary = yearly_volume |&gt; filter(year == 2022) |&gt;\n  arrange(desc(mean_volume)) |&gt;\n  filter(company == \"Apple Inc.\" || company == \"Tesla, Inc.\" || company == \"Amazon.com, Inc.\" || company == \"NVIDIA Corporation\" || company == \"Intel Corporation\") |&gt;\n  ungroup() |&gt;\n  mutate(company = fct_reorder(company, -mean_volume))\n\noptions(scipen=100)\nggplot(data = top_5_summary, aes(x = company, y = mean_volume)) +\n  geom_errorbar(aes(ymin = lower, ymax = upper), col = \"saddlebrown\", width = 0.1, linewidth = 0.75) +\n  geom_point(col = \"darkgreen\", size = 2) +\n  labs(x = \"Company\", y = \"Mean Daily Volume\")\n\n\n\n\nVisual Takeaways: Apple and Tesla are the most popular stocks to trade in 2022, with a mean daily trading volume of nearly 90 million. The error bars are \\(\\pm 1 se\\), and these illustrate the variability in the daily mean for the whole year of 2022. There is far less variance in volume for NVIDIA and Intel companies than Apple, Tesla, and Amazon. This means that there is less volatility in daily trading volume for NVIDIA and Intel Corporations."
  },
  {
    "objectID": "posts/BlogPost2/index.html#for-the-most-popular-company-apple.com-can-we-make-a-model-to-accurately-predict-its-stock-prices",
    "href": "posts/BlogPost2/index.html#for-the-most-popular-company-apple.com-can-we-make-a-model-to-accurately-predict-its-stock-prices",
    "title": "Blog Post #2: Big Tech Stock Prices",
    "section": "For the most popular company (Apple.com), can we make a model to accurately predict its stock prices?",
    "text": "For the most popular company (Apple.com), can we make a model to accurately predict its stock prices?\n\napple_stocks = stocks |&gt; filter(stock_symbol == \"AAPL\")\n\nmod_apple &lt;- lm(high ~ poly(date, degree = 6), data = apple_stocks) \n\ngrid &lt;- apple_stocks |&gt;\n  data_grid(\n    date = seq_range(date, n = 50))\n\naug_apple &lt;- augment(mod_apple, newdata = grid,\n                   interval = \"confidence\")\n\nggplot(data = apple_stocks, aes(x = date, y = high)) +\n  geom_line() +\n  geom_line(data = aug_apple, aes(x = date, y = .fitted),\n            colour = \"blue\", linewidth = 1.2) +\n  geom_ribbon(data = aug_apple, aes(y = .fitted,\n                                  ymin = .lower,\n                                  ymax = .upper), \n              alpha = 0.4) +\n  labs(x = \"Date\", y = \"Stock Price ($)\")\n\n\n\nglance(mod_apple)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     0.978         0.978  7.06    24570.       0     6 -11031. 22078. 22127.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nVisual Takeaways: The black curve is the observed stock prices for Apple.com and the blue curve is the the model used to predict Apple stock prices. Although it’s hard to see, there is also a shaded region around the blue curve that represents the 95% confidence interval for the model’s fitted values. The model seems to fit the actual trend in Apple stock price decently well (\\(R^2 = 0.978\\))."
  },
  {
    "objectID": "posts/BlogPost2/index.html#conclusion",
    "href": "posts/BlogPost2/index.html#conclusion",
    "title": "Blog Post #2: Big Tech Stock Prices",
    "section": "Conclusion",
    "text": "Conclusion\nThis data set was very interesting to explore, and I wish I had more time to delve into the data even deeper. There are certainly some flaws in just using a 6th degree polynomial to model the trend in Apple stock prices as there are certainly better methods that would be more appropriate to model this trend. Additionally, faceting the first graph makes it easier to visualize individual trends in stock prices, but makes it slightly harder to compare trends.\nIf I had more time on this data, I would definitely try to find a better modeling technique to better fit Apple stock prices.\nConnections to Class Ideas\n\nIn the second and third visualizations, I expressed the variability in the data using error bars and a shaded 95% interval region, respectively"
  },
  {
    "objectID": "posts/BlogPost1/index.html",
    "href": "posts/BlogPost1/index.html",
    "title": "Blog Post #1: US Tornado Data Exploration",
    "section": "",
    "text": "These data come from NOAA’s National Weather Service Storm Prediction Center. This data set consists of 27 different variables describing each observed tornado instance (68,693 total observations) in the United States from 1950 to 2022. I found this data set from tidytuesday on GitHub from the following URL: https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-05-16/readme.md.\nQuestions of Interest\n\nHow do total tornado occurrences vary within the United States - which state has seen the most tornadoes over the last 72 years?\nHow has the occurrence of extreme tornadoes (&gt;3F) changed over the last 72 years?\nIn which months are tornadoes most common?\n\nVariables of Interest\n\nyr: year of tornado occurrence\nmo: month of tornado occurrence\nst: two-letter abbreviation for the state\nmag: tornado magnitude on the Fujita Scale (0F-5F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(maps)\nlibrary(RColorBrewer)\n\ntornadoes &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-16/tornados.csv')\nhead(tornadoes)\n\n# A tibble: 6 × 27\n     om    yr    mo    dy date       time  tz    datetime_utc        st      stf\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;     &lt;tim&gt; &lt;chr&gt; &lt;dttm&gt;              &lt;chr&gt; &lt;dbl&gt;\n1   192  1950    10     1 1950-10-01 21:00 Amer… 1950-10-02 03:00:00 OK       40\n2   193  1950    10     9 1950-10-09 02:15 Amer… 1950-10-09 08:15:00 NC       37\n3   195  1950    11    20 1950-11-20 02:20 Amer… 1950-11-20 08:20:00 KY       21\n4   196  1950    11    20 1950-11-20 04:00 Amer… 1950-11-20 10:00:00 KY       21\n5   197  1950    11    20 1950-11-20 07:30 Amer… 1950-11-20 13:30:00 MS       28\n6   194  1950    11     4 1950-11-04 17:00 Amer… 1950-11-04 23:00:00 PA       42\n# ℹ 17 more variables: mag &lt;dbl&gt;, inj &lt;dbl&gt;, fat &lt;dbl&gt;, loss &lt;dbl&gt;, slat &lt;dbl&gt;,\n#   slon &lt;dbl&gt;, elat &lt;dbl&gt;, elon &lt;dbl&gt;, len &lt;dbl&gt;, wid &lt;dbl&gt;, ns &lt;dbl&gt;,\n#   sn &lt;dbl&gt;, f1 &lt;dbl&gt;, f2 &lt;dbl&gt;, f3 &lt;dbl&gt;, f4 &lt;dbl&gt;, fc &lt;lgl&gt;"
  },
  {
    "objectID": "posts/BlogPost1/index.html#tornadoes-data-set-introduction",
    "href": "posts/BlogPost1/index.html#tornadoes-data-set-introduction",
    "title": "Blog Post #1: US Tornado Data Exploration",
    "section": "",
    "text": "These data come from NOAA’s National Weather Service Storm Prediction Center. This data set consists of 27 different variables describing each observed tornado instance (68,693 total observations) in the United States from 1950 to 2022. I found this data set from tidytuesday on GitHub from the following URL: https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-05-16/readme.md.\nQuestions of Interest\n\nHow do total tornado occurrences vary within the United States - which state has seen the most tornadoes over the last 72 years?\nHow has the occurrence of extreme tornadoes (&gt;3F) changed over the last 72 years?\nIn which months are tornadoes most common?\n\nVariables of Interest\n\nyr: year of tornado occurrence\nmo: month of tornado occurrence\nst: two-letter abbreviation for the state\nmag: tornado magnitude on the Fujita Scale (0F-5F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(maps)\nlibrary(RColorBrewer)\n\ntornadoes &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-16/tornados.csv')\nhead(tornadoes)\n\n# A tibble: 6 × 27\n     om    yr    mo    dy date       time  tz    datetime_utc        st      stf\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;     &lt;tim&gt; &lt;chr&gt; &lt;dttm&gt;              &lt;chr&gt; &lt;dbl&gt;\n1   192  1950    10     1 1950-10-01 21:00 Amer… 1950-10-02 03:00:00 OK       40\n2   193  1950    10     9 1950-10-09 02:15 Amer… 1950-10-09 08:15:00 NC       37\n3   195  1950    11    20 1950-11-20 02:20 Amer… 1950-11-20 08:20:00 KY       21\n4   196  1950    11    20 1950-11-20 04:00 Amer… 1950-11-20 10:00:00 KY       21\n5   197  1950    11    20 1950-11-20 07:30 Amer… 1950-11-20 13:30:00 MS       28\n6   194  1950    11     4 1950-11-04 17:00 Amer… 1950-11-04 23:00:00 PA       42\n# ℹ 17 more variables: mag &lt;dbl&gt;, inj &lt;dbl&gt;, fat &lt;dbl&gt;, loss &lt;dbl&gt;, slat &lt;dbl&gt;,\n#   slon &lt;dbl&gt;, elat &lt;dbl&gt;, elon &lt;dbl&gt;, len &lt;dbl&gt;, wid &lt;dbl&gt;, ns &lt;dbl&gt;,\n#   sn &lt;dbl&gt;, f1 &lt;dbl&gt;, f2 &lt;dbl&gt;, f3 &lt;dbl&gt;, f4 &lt;dbl&gt;, fc &lt;lgl&gt;"
  },
  {
    "objectID": "posts/BlogPost1/index.html#how-do-total-tornado-occurrances-vary-within-the-united-states---which-state-has-seen-the-most-tornadoes-over-the-past-72-years",
    "href": "posts/BlogPost1/index.html#how-do-total-tornado-occurrances-vary-within-the-united-states---which-state-has-seen-the-most-tornadoes-over-the-past-72-years",
    "title": "Blog Post #1: US Tornado Data Exploration",
    "section": "How do total tornado occurrances vary within the United States - which state has seen the most tornadoes over the past 72 years?",
    "text": "How do total tornado occurrances vary within the United States - which state has seen the most tornadoes over the past 72 years?\n\nstate_df &lt;- map_data(\"state\")\n\nstate_abbrev = state_df |&gt; mutate(state = case_when(region == \"alabama\" ~ \"AL\",\n                                  region == \"alaska\" ~ \"AK\",\n                                  region == \"arizona\" ~ \"AZ\",\n                                  region == \"arkansas\" ~ \"AR\",\n                                  region == \"california\" ~ \"CA\",\n                                  region == \"colorado\" ~ \"CO\",\n                                  region == \"connecticut\" ~ \"CT\",\n                                  region == \"delaware\" ~ \"DE\",\n                                  region == \"florida\" ~ \"FL\",\n                                  region == \"georgia\" ~ \"GA\",\n                                  region == \"hawaii\" ~ \"HI\",\n                                  region == \"idaho\" ~ \"ID\",\n                                  region == \"illinois\" ~ \"IL\",\n                                  region == \"indiana\" ~ \"IN\",\n                                  region == \"iowa\" ~ \"IA\",\n                                  region == \"kansas\" ~ \"KS\",\n                                  region == \"kentucky\" ~ \"KY\",\n                                  region == \"louisiana\" ~ \"LA\",\n                                  region == \"maine\" ~ \"ME\",\n                                  region == \"maryland\" ~ \"MD\",\n                                  region == \"massachusetts\" ~ \"MA\",\n                                  region == \"michigan\" ~ \"MI\",\n                                  region == \"minnesota\" ~ \"MN\",\n                                  region == \"mississippi\" ~ \"MS\",\n                                  region == \"missouri\" ~ \"MO\",\n                                  region == \"montana\" ~ \"MT\",\n                                  region == \"nebraska\" ~ \"NE\",\n                                  region == \"nevada\" ~ \"NV\",\n                                  region == \"new hampshire\" ~ \"NH\",\n                                  region == \"new jersey\" ~ \"NJ\",\n                                  region == \"new mexico\" ~ \"NM\",\n                                  region == \"new york\" ~ \"NY\",\n                                  region == \"north carolina\" ~ \"NC\",\n                                  region == \"north dakota\" ~ \"ND\",\n                                  region == \"ohio\" ~ \"OH\",\n                                  region == \"oklahoma\" ~ \"OK\",\n                                  region == \"oregon\" ~ \"OR\",\n                                  region == \"pennsylvania\" ~ \"PA\",\n                                  region == \"rhode island\" ~ \"RI\",\n                                  region == \"south carolina\" ~ \"SC\",\n                                  region == \"south dakota\" ~ \"SD\",\n                                  region == \"tennessee\" ~ \"TN\",\n                                  region == \"texas\" ~ \"TX\",\n                                  region == \"utah\" ~ \"UT\",\n                                  region == \"vermont\" ~ \"VT\",\n                                  region == \"virginia\" ~ \"VA\",\n                                  region == \"washington\" ~ \"WA\",\n                                  region == \"west virginia\" ~ \"WV\",\n                                  region == \"wisconsin\" ~ \"WI\",\n                                  region == \"wyoming\" ~ \"WY\",\n                                  TRUE ~ NA_character_))\n\ntornadoes_summary = tornadoes |&gt; group_by(st) |&gt;\n  summarise(total_tornadoes = n(),\n            mean_magnitude = mean(mag),\n            mean_injuries = mean(inj),\n            mean_fatalities = mean(fat),\n            mean_property_loss = mean(loss),\n            mean_length = mean(len),\n            mean_width = mean(wid))\n\nstate_tornadoes = left_join(state_abbrev, tornadoes_summary, by = c(\"state\" = \"st\"))\n\nmap_totaltornadoes = ggplot(data = state_tornadoes,\n            mapping = aes(x = long, y = lat,\n                          group = group)) +\n  geom_polygon(colour = \"black\", aes(fill = total_tornadoes)) +\n  coord_map(projection = \"albers\", lat0 = 39, lat1 = 45) +\n  theme_void() +\n  scale_fill_distiller(palette = \"Reds\", direction = 0.5)\n\nmap_totaltornadoes\n\n\n\n\n\nggsave(here(\"posts/BlogPost1/total_tornadoes_map.png\"), map_totaltornadoes)\n\nVisual Takeaways: This is a map of the United States, colored by total tornado instances over the past 72 years. Texas stands out as having a significantly higher number of tornadoes than the rest of the country. This may be surprising, as one might expect either Kansas or Oklahoma to take the top spot (while those two states appear to be coming in the second and third most tornadoes). One possible explanation is that Texas is significantly larger in terms of pure land area. One visible trend is “tornado alley” through the center of the United States from Texas through South Dakota (including eastern Colorado). Florida is also an interesting case, having a similar number of tornadoes to states in tornado alley. This makes sense because tornadoes often occur during other severe storm events such as thunderstorms, tropical storms, and hurricanes."
  },
  {
    "objectID": "posts/BlogPost1/index.html#how-has-the-occurrence-of-extreme-tornadoes-3f-changed-over-the-last-72-years",
    "href": "posts/BlogPost1/index.html#how-has-the-occurrence-of-extreme-tornadoes-3f-changed-over-the-last-72-years",
    "title": "Blog Post #1: US Tornado Data Exploration",
    "section": "How has the occurrence of extreme tornadoes (>3F) changed over the last 72 years?",
    "text": "How has the occurrence of extreme tornadoes (&gt;3F) changed over the last 72 years?\n\ntornadoes_mag_sum = tornadoes |&gt; filter(mag &gt; 2) |&gt;\n  group_by(yr,mag) |&gt;\n  summarise(tornado_occurrences = n()) |&gt;\n  mutate(mag = as_factor(mag))\n\nggplot(data = tornadoes_mag_sum, aes(x = yr, y = tornado_occurrences, col = mag)) +\n  geom_line(linewidth = 0.75) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(x = \"Year\", y = \"Severe Tornado Occurences\") +\n  theme_minimal()\n\n\n\n\nVisual Takeaways: There doesn’t appear to be any strong trend in extreme tornadoes in the United States. The trend for severe (3F: 158-206 mph), devastating (4F: 207-260 mph), and incredible (5F: 261-318 mph) tornadoes seems to be random and relatively unpredictable. With increasing instability in the environment due to global climate change, I expected to see an increase in more intense tornadoes from 1950 to 2022. For severe tornadoes, however, there has been a slight overall decrease in occurrences over time."
  },
  {
    "objectID": "posts/BlogPost1/index.html#in-which-months-are-tornadoes-most-common",
    "href": "posts/BlogPost1/index.html#in-which-months-are-tornadoes-most-common",
    "title": "Blog Post #1: US Tornado Data Exploration",
    "section": "In which months are tornadoes most common?",
    "text": "In which months are tornadoes most common?\n\nmonth_tornado = tornadoes |&gt;\n  group_by(mo) |&gt;\n  summarise(Month_totals = n()) |&gt;\n  mutate(Month = case_when(mo == 1 ~ \"Jan\",\n                           mo == 2 ~ \"Feb\",\n                           mo == 3 ~ \"Mar\",\n                           mo == 4 ~ \"Apr\",\n                           mo == 5 ~ \"May\",\n                           mo == 6 ~ \"Jun\",\n                           mo == 7 ~ \"Jul\",\n                           mo == 8 ~ \"Aug\",\n                           mo == 9 ~ \"Sep\",\n                           mo == 10 ~ \"Oct\",\n                           mo == 11 ~ \"Nov\",\n                           mo == 12 ~ \"Dec\")) |&gt;\n  mutate(Month = as.factor(x = Month),\n         Month = fct_reorder(Month, mo))\n\ntop_3 = month_tornado |&gt;\n  filter(Month %in% c(\"Apr\", \"May\", \"Jun\"))\n\nggplot(data = month_tornado, aes(x = Month, y = Month_totals)) +\n  geom_segment(aes(xend = Month, y = 0, yend = Month_totals)) +\n  geom_point() +\n  geom_segment(data = top_3, aes(xend = Month, y = 0, yend = Month_totals), col = \"darkred\", linewidth = 2) +\n  geom_point(data = top_3, col = \"darkred\", size = 3) +\n  labs(y = \"Tornado Occurrences\") +\n  theme_minimal()\n\n\n\n\nVisual Takeaway: The most tornadoes occur during the start of summer - particularly April, May, and June. These three months seem significantly higher than the rest, which makes sense due to the typical atmospheric conditions that exist during this time. The introduction of more warm, moist air, combined with cooler, dry air causes instability in the lower atmosphere. The dryness of the winter months lead to lower instances of tornadoes in the United States."
  },
  {
    "objectID": "posts/BlogPost1/index.html#conclusion",
    "href": "posts/BlogPost1/index.html#conclusion",
    "title": "Blog Post #1: US Tornado Data Exploration",
    "section": "Conclusion",
    "text": "Conclusion\nIn particular for the map of total tornadoes, I could standardize the values with respect to tornadoes per state land area so that the massive area of Texas doesn’t stand out as much in the visualization. If I did it this way, I would likely see a change in colors in the map with likely higher values in states like Oklahoma and Kansas. In terms of the line plot for extreme tornadoes over time, the plot is a bit underwhelming. This is likely because of the lack of striking trend that we see in the other two figures.\nIf I had more time to work with these data, I would try to explore relationships involving tornado size (length and width) and magnitude with property losses and injuries/fatalities. I think it would be interesting to see if I could make a model that predicts either property loss or injuries/fatalities using tornado size and magnitude as well as time of day. The datetime_utc variable could also be used to view the data as a time series."
  },
  {
    "objectID": "posts/BlogPost1/index.html#connection-to-class-ideas",
    "href": "posts/BlogPost1/index.html#connection-to-class-ideas",
    "title": "Blog Post #1: US Tornado Data Exploration",
    "section": "Connection to Class Ideas",
    "text": "Connection to Class Ideas\nThese visuals effectively communicate information about tornado data in the United States by incorporating color, cleanliness, and organization to appeal to the reader’s visual senses. In terms of human perception, changes in color are much easier to distinguish than changes in shape, so I made sure to use color that grabs the reader’s attention whenever applicable. For the map of the United States, I used a sequential, continuous color scale to represent the total number of tornado occurrences per state. This color scale is ideal for representing this type of data because it allows for a quick, effective interpretation of the intended results. Finally, I tried to maximize data-to-ink ratio as much as possible to ensure the reader’s attention was in the right place and not distracted by any superfluous detail."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DATA334blog",
    "section": "",
    "text": "Blog Post #2: Big Tech Stock Prices\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2024\n\n\nBrody Pinto\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post #1: US Tornado Data Exploration\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nBrody Pinto\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2024\n\n\nBrody Pinto\n\n\n\n\n\n\nNo matching items"
  }
]